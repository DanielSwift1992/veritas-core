# Production-grade Roadmap for Δ-Kernel Repository

> This document enumerates everything that remains to be converted from the current proof-of-concept into a *fully verifiable, publication-ready* artifact.  It can serve as the team's shared TODO list; CI should fail once any checkbox marked `TODO` is left unchecked in the final release.

## 1  Lean Core

| Block | Current state | Required for "honest = exact" | Technique / code snippet |
|-------|---------------|-------------------------------|---------------------------|
| **Lean core** | All current core files compile, **0 `#sorry`**. Several correspondences are still marked `partial/none` in `status.yml` (e.g. Shannon, HJB, Navier–Stokes). | 1. Complete the remaining partial proofs (`Shannon`, `EulerLagrange`, etc.).<br>2. Add new files `GradientDesc.lean`, `FFTGeom.lean`, and hook them into `TableCorrespondence`. | **Minimal example (Landauer bound):**
```lean
import Mathlib.Data.Real.Log
open Real

theorem landauer_exact (T : ℝ) (hT : T > 0) :
    (Real.log 2) * T ≥ 0 := by
  have hlog : Real.log 2 > 0 := by
    have : (2 : ℝ) > 1 := by norm_num
    exact Real.log_pos this
  have : 0 ≤ Real.log 2 := le_of_lt hlog
  have : 0 ≤ T := le_of_lt hT
  simpa using mul_nonneg ‹0 ≤ Real.log 2› this
```|

---

## 2  pytest / Numeric demos

| Item | What to add |
|------|-------------|
| Landauer | already covered |
| Shannon | already covered |
| Navier–Stokes | **DONE** (1-D Stokes mini-solver in `stokes_mini.py`). *Optional*: extend to 2-D grid (ν = 1) and tighten tolerance. |
| Fokker–Planck | **DONE** (see `ou_chain_entropy.py` & `fokker_planck_entropy.py`). |
| Nash | **DONE** (`nash_gradient.py` pure-Python gradient descent). *Optional*: switch to PyTorch to benchmark GPU throughput. |
| FFT geometry | **DONE** (`fft_ops.py`). |

Each demo must expose:
```python
def f_dot_grad_p(*params) -> float: ...
def theoretical(*params) -> float: ...
assert np.allclose(f_dot_grad_p(...), theoretical(...))
```
so that the test-runner can discover and tabulate automatically.

---

## 3  Continuous Integration

* `requirements-dev.txt` → numpy, torch (if used), ruff, black.
* GitHub Action matrix `{ ubuntu-latest, macos-latest }`.
* Optional `docker-compose.yml` for local multiplatform reproduction.

---

## 4  Documentation

* Update `README.md` with a machine-generated table "Lean-verified vs Numeric-verified".
* `paper/suppA_lean_outline.tex` to be autogenerated by `gen_lean_index.py`.

---

## 5  Code Quality

* Enforce `ruff` + `black` via *pre-commit* hooks.
* Remove C++ demo; prefer Python + Numba to keep dependency surface consistent.

---

## 6  Neuroscience Energy (Spike)

* In `hh_spike.py` print
  ```text
  bits = ΔE / (k_B * T * ln 2)
  ```
  Compare with literature (≈ 10³ bits per spike).

---

## 7  Repo Concatenation Utility

* Extend `concat_repo.py` with `--sha` flag that appends SHA-256 of every included file for long-term archiving / Zenodo bundles.

---

## 8  Zenodo Release

When CI is ✨ green:
1. Tag version `v0.1`.
2. Upload archive + `repo_concat.txt` to Zenodo.
3. Insert DOI in README, LaTeX main paper, and Abstract.

---

**Checklist (CI to enforce):**
- [ ] All Lean files compile with `0 #sorry`.
- [ ] `pytest` discovers 13 tests (12 numeric demos + Lean compile) and all pass within ≤ 10 seconds each.
- [ ] README table is up-to-date.
- [ ] `repo_concat --sha` passes and includes every Lean/Python file.
- [ ] Zenodo DOI present.

Once all boxes ticked, the repository is a *self-verifying artifact*: one CI run = one published quantitative claim, with no hand-wave.